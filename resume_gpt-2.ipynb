{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac7937b-c395-47ab-80a5-e9d560df5515",
   "metadata": {},
   "source": [
    "# Resume Processing Main Notebook\n",
    "\n",
    "## Things to do \n",
    "1) load different formats of files for eg txt, pdf, docx\n",
    "2) extract text from the file\n",
    "3) Create prompt for the file\n",
    "4) Use instructor and other libraries to get structured output from gpt\n",
    "5) Parse the output in json to be ready to send to api\n",
    "6) Create prompts for asking additional questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84fa38f-2a62-4c45-9349-e026d248fd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'magic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmagic\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'magic'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import magic\n",
    "import PyPDF2\n",
    "import docx\n",
    "import base64\n",
    "import datetime\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03845f-fc08-43f8-843e-c54b92f4d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from typing_extensions import override\n",
    "import ast\n",
    "# from pypdf import PdfReader\n",
    "\n",
    "api_key = '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'\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fcdfb-7869-4d76-a254-60910c9e128c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353bada-a06d-44c1-9482-39c68b656833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_txt(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a .txt file.\n",
    "    Args:\n",
    "        file_path (str): Path to the .txt file.\n",
    "    Returns:\n",
    "        str: Text extracted from the .txt file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a .pdf file.\n",
    "    Args:\n",
    "        file_path (str): Path to the .pdf file.\n",
    "    Returns:\n",
    "        str: Text extracted from the .pdf file.\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a .docx file.\n",
    "    Args:\n",
    "        file_path (str): Path to the .docx file.\n",
    "    Returns:\n",
    "        str: Text extracted from the .docx file.\n",
    "    \"\"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    text = ''\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + '\\n'\n",
    "    return text\n",
    "\n",
    "def identify_file_type(file_path):\n",
    "    \"\"\"\n",
    "    Identifies the MIME type of the file.\n",
    "    Args:\n",
    "        file_path (str): Path to the file.\n",
    "    Returns:\n",
    "        str: MIME type of the file.\n",
    "    \"\"\"\n",
    "    mime_type = magic.Magic(mime=True)\n",
    "    file_type = mime_type.from_file(file_path)\n",
    "    return file_type\n",
    "\n",
    "def extract_text(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a file based on its type (.txt, .pdf, .docx).\n",
    "    Args:\n",
    "        file_path (str): Path to the file.\n",
    "    Returns:\n",
    "        str: Text extracted from the file.\n",
    "    \"\"\"\n",
    "    file_type = identify_file_type(file_path)\n",
    "    if file_type == 'text/plain':\n",
    "        return extract_text_from_txt(file_path)\n",
    "    elif file_type == 'application/pdf':\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        return \"Unsupported file format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0304d-aefa-4cbe-93b1-bca156052751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_path = '../../kuldeep_resume_long_version.pdf'\n",
    "text = extract_text(file_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defe9c5-a71b-4b15-b79b-96ebf570eb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from flask import request\n",
    "\n",
    "# # Assuming your API endpoint is defined in a Flask route\n",
    "\n",
    "# @app.route('/upload', methods=['POST'])\n",
    "# def upload():\n",
    "#   if request.method == 'POST':\n",
    "#     # Access the base64 encoded string from the request body (replace 'data' with the actual key)\n",
    "#     encoded_data = request.json['data']\n",
    "    \n",
    "#     # Decode the base64 string\n",
    "#     decoded_data = base64.b64decode(encoded_data)\n",
    "    \n",
    "#     # Get the file mime type using the magic library\n",
    "#     mime_type = magic.from_buffer(decoded_data, mime=True)\n",
    "    \n",
    "#     # Handle different file types based on mime type\n",
    "#     if mime_type == 'application/pdf':\n",
    "#         # Process PDF file (e.g., using external libraries like PyMuPDF)\n",
    "#         # ...\n",
    "#     elif mime_type in ('text/plain', 'text/x-plain'):\n",
    "#         # Process text file (assuming UTF-8 encoding)\n",
    "#         content = decoded_data.decode()\n",
    "#     elif mime_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':\n",
    "#         # Process DOCX file (e.g., using external libraries like python-docx)\n",
    "#         # ...\n",
    "#     else:\n",
    "#         return \"Unsupported file format!\", 415\n",
    "\n",
    "#     # Process the content using your model (replace with your specific logic)\n",
    "#     # ...\n",
    "    \n",
    "#     return \"File uploaded and processed successfully!\"\n",
    "#   else:\n",
    "#     return \"Unsupported method\", 405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a8d6e-ee32-41de-9cfe-6e48045dc2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Contact(BaseModel):\n",
    "    phone_number: str\n",
    "    email: str\n",
    "\n",
    "    \n",
    "class PersonalInfo(BaseModel):\n",
    "    name: str\n",
    "    contact_info: Contact\n",
    "    linkedin_url: Optional[str]\n",
    "\n",
    "    \n",
    "class Education(BaseModel):\n",
    "    degree: str\n",
    "    majors: str\n",
    "    institution: str\n",
    "    graduation_date: Optional[str]\n",
    "    gpa: Optional[float]\n",
    "\n",
    "\n",
    "class Responsibility(BaseModel):\n",
    "    responsibility: str\n",
    "    \n",
    "    \n",
    "class WorkExperience(BaseModel):\n",
    "    job_title: str\n",
    "    dates_of_employment: Optional[str]\n",
    "    company: str\n",
    "    location: Optional[str]\n",
    "    responsibilities: List[Responsibility]\n",
    "    \n",
    "\n",
    "class SkillSubclass(BaseModel):\n",
    "    skill: str\n",
    "\n",
    "\n",
    "class Skills(BaseModel):\n",
    "    technical_skills: List[SkillSubclass]\n",
    "    soft_skills: List[SkillSubclass]\n",
    "    general_skills: Optional[List[str]]\n",
    "\n",
    "class Projects(BaseModel):\n",
    "    project_title: str\n",
    "    description: str\n",
    "    dates: Optional[str]\n",
    "    contribution: str\n",
    "\n",
    "class VolunteerWork(BaseModel):\n",
    "    organization: str\n",
    "    contribution: Optional[str]\n",
    "\n",
    "\n",
    "class Awards(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str]\n",
    "    \n",
    "\n",
    "class Certifications(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56be2e-5224-4317-81c6-533280616b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResumeObj(BaseModel):\n",
    "    personal_info: PersonalInfo\n",
    "    education: List[Education]\n",
    "    work_exp: List[WorkExperience]\n",
    "    skills: Skills\n",
    "    projects: List[Projects]\n",
    "    certifications: List[Certifications]\n",
    "    awards: List[Awards]\n",
    "    volunteer_work: List[VolunteerWork]\n",
    "    additional_info: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16ab54-ebfd-4d59-bf8c-64136f22c624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = ResumeObj.model_json_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2621f6-c2f0-48ee-a3ba-7e5393fb423c",
   "metadata": {},
   "source": [
    "### Finalize the schema with Divya, Shafiq, Rainy and Siddak and convert to YAML for Shafiq to share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99862e2-ea11-45d0-aad0-f33c6be3b609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are expert Resume Parsing System. Given the text from a resume your task is to extract information and provide it in json formation.\n",
    "\n",
    "{}\n",
    "\"\"\".format(text)\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f222f-093d-40d4-80cd-cd9928f02477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    functions=[{\"name\": \"ResumeParse\", \"parameters\": schema}],\n",
    "    function_call=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a2fdd-2fe9-48e4-ab1c-0fcf35062a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ResumeObj.model_validate_json(resp.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda045a-77bb-4717-b8d2-11565c61d294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_json_object = json.loads(resp.choices[0].message.function_call.arguments)\n",
    "resume_json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7581f-ac1c-4be3-8626-23e15e551e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd21ee3-19b4-4d56-8f22-68c2a035bfaf",
   "metadata": {},
   "source": [
    "### using instructor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755eb26-fcd6-449f-b27d-191fd4b863d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# patch the client to add `response_model` to the `create` method\n",
    "client = instructor.patch(OpenAI(api_key=api_key), mode=instructor.Mode.FUNCTIONS) # mode can be FUNCTIONS (uses function calling), TOOLS , JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d15551-15c5-4fd2-ae3f-1a1989f5e424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    response_model=ResumeObj,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87a30a-bacb-42fa-a2ff-a965a4c9c065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp.personal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Rainy & Siddak\n",
    "\n",
    "# Do we just need information from Resume to sift through the O net Data\n",
    "# or Do we need information for some other backend related purposes too. \n",
    "\n",
    "# Normalize the output of GPT3 using the keys and values from the Onet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e410c0e-8467-48ee-a856-b2d4d48b51d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROMPT = '''\n",
    "# You are expert Resume Parsing System. Given the text from a resume \\\n",
    "# your task is to extract information and provide it in a json formati. \n",
    "\n",
    "# 1.Personal Information:\n",
    "#     Full name\n",
    "#     Contact information (phone number, email address, physical address)\n",
    "#     LinkedIn profile (if available)\n",
    "#     Professional Summary/Objective: A brief overview of the individual's career goals, skills, and experiences.\n",
    "\n",
    "# 2. Education:\n",
    "#     Degrees earned (include majors/minors)\n",
    "#     Name of institution(s)\n",
    "#     Graduation dates\n",
    "#     GPA (if relevant)\n",
    "\n",
    "# 3. Work Experience:\n",
    "#     List of previous jobs in reverse chronological order\n",
    "#     Job titles\n",
    "#     Dates of employment\n",
    "#     Company/Organization names\n",
    "#     Job responsibilities and achievements\n",
    "#     Any promotions or notable projects\n",
    "\n",
    "# 4. Skills:\n",
    "#     Technical skills (e.g., programming languages, software proficiency)\n",
    "#     Soft skills (e.g., communication, leadership, teamwork)\n",
    "#     Industry-specific skills (relevant to the person's career field)\n",
    "\n",
    "# 5. Certifications/Licenses:\n",
    "#     Any relevant certifications or licenses obtained\n",
    "#     Name of certification/license\n",
    "#     Issuing organization\n",
    "#     Dates obtained/expiration dates\n",
    "\n",
    "# 6. Awards/Honors:\n",
    "#     Any recognition or awards received related to work or education\n",
    "#     Volunteer Experience:\n",
    "\n",
    "# 7. Any volunteer work or community involvement\n",
    "#     Organization names\n",
    "#     Dates of involvement\n",
    "#     Roles and responsibilities\n",
    "#     Professional Affiliations:\n",
    "\n",
    "# 8. Memberships in professional organizations\n",
    "#     Leadership roles within these organizations (if applicable)\n",
    "\n",
    "# 9. Projects:\n",
    "#     Relevant projects completed either academically or professionally\n",
    "#     Description of the project\n",
    "#     Individual's role and contributions\n",
    "\n",
    "# 10. Career Objectives:\n",
    "#     Long-term career aspirations\n",
    "#     Short-term career goals\n",
    "#     Additional Information:\n",
    "\n",
    "\n",
    "# Resume : {}\n",
    "\n",
    "# Extract information related to all the points mentioned and provide it in a json format.\n",
    "# '''.format(resume)\n",
    "\n",
    "# print(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e5fc7-ace3-4053-bae1-a556af3b77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should extract information related to the below areas :\n",
    "# 1) General Background Information : information related to the name, websites provided, age etc.\n",
    "# 2) Educational Background Information : information related to the schools and colleges attended and their start and end dates, also \\\n",
    "# degree related information\n",
    "# 3) Knowledge Information : Summarize the work and project experience in points which tell about the fields the person is knowledgable in\n",
    "# 4) Skills Information : Provide a list of all the skills menioned in the resume \n",
    "# 5) Achievements : information related to any achievements or awards received.\n",
    "# 6) Work Experience : Summarize the work experience in the resume and provide in a list of two three points.\n",
    "# 7) Extrac-Curriculars : Summarize the extrac curriculars mentioned and provide in a list with two, three points.\n",
    "# 8) Overview : Provide a general of the resume strong and weak points and skills and knowledge in two to three lines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10b0b4-e844-4bf6-972e-1ce4a14a1c5e",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "**Data Integration**: Combine the information from the resume (such as skills, education, work experience) with the relevant data from the ONet Online dataset. Match the skills mentioned in the resume with the skills required for various jobs in the ONet Online dataset.\n",
    "\n",
    "\n",
    "**Natural Language Processing (NLP)**: Utilize NLP techniques to extract key information from the resume text, such as skills, education, and work experience. Use NLP models to analyze the job descriptions from the ONet Online dataset to identify required skills, qualifications, and job duties.\n",
    "\n",
    "**Skill Matching**:Develop algorithms to match the skills and qualifications mentioned in the resume with the requirements of different jobs in the ONet Online dataset. Assign weights or scores to the matches based on relevance and importance.\n",
    "\n",
    "\n",
    "**Job Recommendations**: Based on the matching results, generate personalized job recommendations for the individual. Prioritize job recommendations based on the best fit with the individual's skills, experience, and career goals.\n",
    "\n",
    "\n",
    "**Career Path Analysis**: Analyze the individual's education, work experience, skills, and career objectives to identify potential career paths. Use data from the ONet Online dataset to explore different career trajectories, job opportunities, and growth prospects within relevant industries.\n",
    "\n",
    "**Education and Training Recommendations**: Recommend additional education, training programs, or certifications based on the individual's career goals and the requirements of their desired jobs. Leverage ONet Online data to suggest relevant courses, certifications, or skill development programs.\n",
    "\n",
    "**Feedback and Iteration**: Incorporate feedback from the individual to improve the accuracy and relevance of job recommendations and career counseling advice. Continuously update the system with new data from the ONet Online dataset and refine the algorithms to enhance performance.\n",
    "User Interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bea40-b3dc-4e37-9037-819a4f6bcf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
